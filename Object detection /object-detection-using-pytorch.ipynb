{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction to Object Detection Notebook using PyTorch\n","\n","This notebook showcases the implementation of object detection using the PyTorch library. \n","`Object detection` is a fundamental computer vision task that involves identifying and localizing objects of interest within an image or video.\n","\n","The primary focus of this notebook is to demonstrate the training process of an object detection model using PyTorch. The model has undergone an extensive training period of 60 hours, with each epoch spanning for 2 hours. The longer training duration allows for more comprehensive learning and refinement of the model's parameters, enabling improved detection accuracy.\n","\n","`PyTorch`, a popular deep learning framework, provides a flexible and efficient platform for building and training object detection models. It offers a wide range of pre-built modules and tools that streamline the development process and facilitate the integration of advanced techniques.\n","\n","Throughout this notebook, we will explore the step-by-step implementation of the object detection pipeline, including data preprocessing, model architecture, loss functions, and optimization strategies. We will also utilize commonly used datasets and evaluation metrics to assess the performance of the trained model.\n","\n","By the end of this notebook, you will have gained a practical understanding of object detection using PyTorch and will be able to apply this knowledge to your own computer vision projects. The comprehensive training process and utilization of the PyTorch library ensure that the resulting model will have a solid foundation for accurate object detection in various real-world scenarios."]},{"cell_type":"markdown","metadata":{},"source":["## Install and Load the PyCocoTool library"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:00.617952Z","iopub.status.busy":"2023-05-31T01:55:00.617554Z","iopub.status.idle":"2023-05-31T01:55:41.801125Z","shell.execute_reply":"2023-05-31T01:55:41.799783Z","shell.execute_reply.started":"2023-05-31T01:55:00.617921Z"},"trusted":true},"outputs":[],"source":["import pycocotools"]},{"cell_type":"markdown","metadata":{},"source":["## Import the required libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:41.814020Z","iopub.status.busy":"2023-05-31T01:55:41.813584Z","iopub.status.idle":"2023-05-31T01:55:45.180048Z","shell.execute_reply":"2023-05-31T01:55:45.179171Z","shell.execute_reply.started":"2023-05-31T01:55:41.813980Z"},"trusted":true},"outputs":[],"source":["import PIL.Image\n","import random\n","import torch\n","import torch.utils.data\n","import numpy as np\n","from collections import defaultdict\n","import torchvision.datasets as dset\n","\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","\n","import torchvision\n","torchvision.disable_beta_transforms_warning()\n","\n","from torchvision import models\n","\n","import torchvision.transforms as original_transforms\n","import torchvision.transforms.v2 as transforms\n","from torchvision.transforms.v2 import functional as F\n","from torchvision.utils import draw_bounding_boxes\n","import multiprocessing as mp\n","from torch import nn\n","import torch.optim as optim\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Set the Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.183895Z","iopub.status.busy":"2023-05-31T01:55:45.183232Z","iopub.status.idle":"2023-05-31T01:55:45.192433Z","shell.execute_reply":"2023-05-31T01:55:45.190930Z","shell.execute_reply.started":"2023-05-31T01:55:45.183858Z"},"trusted":true},"outputs":[],"source":["n_gpus = torch.cuda.device_count()\n","USING_CPU = not torch.cuda.is_available()\n","\n","DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available()  and n_gpus > 0) else \"mps\")\n","kwargs = {'num_workers': mp.cpu_count() , 'pin_memory': True} if DEVICE.type=='cuda' else {'num_workers': mp.cpu_count()//2, 'prefetch_factor': 4}\n","\n","print(f'Num of CPUs: {mp.cpu_count()}')\n","print(f'Device in use: {DEVICE}')\n","print(f'Found {n_gpus} GPU Device/s.')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.194011Z","iopub.status.busy":"2023-05-31T01:55:45.193684Z","iopub.status.idle":"2023-05-31T01:55:45.209238Z","shell.execute_reply":"2023-05-31T01:55:45.208131Z","shell.execute_reply.started":"2023-05-31T01:55:45.193979Z"},"trusted":true},"outputs":[],"source":["kwargs, USING_CPU"]},{"cell_type":"markdown","metadata":{},"source":["## Create a dataset loader that gives a coco datasset"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-31T01:55:45.210777Z","iopub.status.busy":"2023-05-31T01:55:45.210453Z","iopub.status.idle":"2023-05-31T01:55:45.221141Z","shell.execute_reply":"2023-05-31T01:55:45.219963Z","shell.execute_reply.started":"2023-05-31T01:55:45.210749Z"},"trusted":true},"outputs":[],"source":["TRAIN_IMG_DIR = 'coco2017/train2017'\n","TRAIN_ANN_FILE = 'coco2017/annotations/instances_train2017.json'\n","USE_PRETRAINED = False\n","SAVED_MODEL_PATH = '/kaggle/input/object-detection-using-pytorch/ssd300_vgg16_checkpoint_2'\n","\n","def load_dataset(transform):\n","    return dset.CocoDetection(root = TRAIN_IMG_DIR, \n","                              annFile = TRAIN_ANN_FILE)\n","\n","coco_train = load_dataset(transform=original_transforms.ToTensor())\n","print(\"Number of samples: \", len(coco_train))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coco_train[0][0]"]},{"cell_type":"markdown","metadata":{},"source":["## Create the required Data Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.223462Z","iopub.status.busy":"2023-05-31T01:55:45.222976Z","iopub.status.idle":"2023-05-31T01:55:45.238153Z","shell.execute_reply":"2023-05-31T01:55:45.237062Z","shell.execute_reply.started":"2023-05-31T01:55:45.223421Z"},"trusted":true},"outputs":[],"source":["class RandomHorizontalFlip(object):\n","    def __init__(self, p=0.5):\n","        self.p = p\n","        self.hf = transforms.RandomHorizontalFlip(1)\n","        \n","    def __call__(self, img, bboxes):\n","        \n","        if torch.rand(1)[0] < self.p:            \n","            img = self.hf.forward(img)\n","            bboxes = self.hf.forward(bboxes)\n","        \n","        return img, bboxes\n","    \n","    \n","class RandomVerticalFlip(object):\n","    def __init__(self, p=0.5):\n","        self.p = p\n","        self.vf = transforms.RandomVerticalFlip(1)\n","        \n","    def __call__(self, img, bboxes):\n","        if torch.rand(1)[0] < self.p:                    \n","            img = self.vf.forward(img)\n","            bboxes = self.vf.forward(bboxes)\n","        \n","        return img, bboxes\n","\n","class Resize(object):\n","    def __init__(self, size):\n","        self.size = size\n","        self.resize = transforms.Resize(self.size, antialias=True)\n","        \n","    def __call__(self, img, bboxes):\n","        img = self.resize.forward(img)\n","        \n","        bboxes = self.resize.forward(bboxes)\n","\n","        return img, bboxes\n"]},{"cell_type":"markdown","metadata":{},"source":["## Simple function to display the sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.239853Z","iopub.status.busy":"2023-05-31T01:55:45.239497Z","iopub.status.idle":"2023-05-31T01:55:45.250744Z","shell.execute_reply":"2023-05-31T01:55:45.249635Z","shell.execute_reply.started":"2023-05-31T01:55:45.239823Z"},"trusted":true},"outputs":[],"source":["def show(sample):\n","    import matplotlib.pyplot as plt\n","\n","    from torchvision.transforms.v2 import functional as F\n","    from torchvision.utils import draw_bounding_boxes\n","    \n","    resize = Resize((300, 300))\n","    \n","    rhf = RandomHorizontalFlip()\n","    rvf = RandomVerticalFlip()\n","    image, target = sample\n","    \n","    image, bboxes = image,target[\"boxes\"] \n","\n","    \n","    image, bboxes = resize(image, bboxes)\n","    image, bboxes = rhf(image, bboxes)\n","    image, bboxes = rvf(image, bboxes)\n","    \n","    if isinstance(image, PIL.Image.Image):\n","        image = F.to_tensor(image)\n","        \n","    image = F.convert_image_dtype(image, torch.uint8)\n","    annotated_image = draw_bounding_boxes(image, bboxes, colors=\"yellow\", width=3)\n","\n","    fig, ax = plt.subplots()\n","    ax.imshow(annotated_image.permute(1, 2, 0).numpy())\n","    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","    fig.tight_layout()\n","\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.252431Z","iopub.status.busy":"2023-05-31T01:55:45.251997Z","iopub.status.idle":"2023-05-31T01:55:45.267979Z","shell.execute_reply":"2023-05-31T01:55:45.266887Z","shell.execute_reply.started":"2023-05-31T01:55:45.252398Z"},"trusted":true},"outputs":[],"source":["sample = coco_train[0]\n","image, target = sample\n","print(type(image))\n","print(type(target), type(target[0]), list(target[0].keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.272479Z","iopub.status.busy":"2023-05-31T01:55:45.272115Z","iopub.status.idle":"2023-05-31T01:55:45.280331Z","shell.execute_reply":"2023-05-31T01:55:45.279186Z","shell.execute_reply.started":"2023-05-31T01:55:45.272444Z"},"trusted":true},"outputs":[],"source":["coco_train = dset.wrap_dataset_for_transforms_v2(coco_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.284267Z","iopub.status.busy":"2023-05-31T01:55:45.283698Z","iopub.status.idle":"2023-05-31T01:55:45.291961Z","shell.execute_reply":"2023-05-31T01:55:45.291071Z","shell.execute_reply.started":"2023-05-31T01:55:45.284223Z"},"trusted":true},"outputs":[],"source":["sample = coco_train[0]\n","image, target = sample\n","print(type(image))\n","print(type(target), list(target.keys()))\n","print(type(target[\"boxes\"]), type(target[\"labels\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.293835Z","iopub.status.busy":"2023-05-31T01:55:45.293375Z","iopub.status.idle":"2023-05-31T01:55:45.303161Z","shell.execute_reply":"2023-05-31T01:55:45.302183Z","shell.execute_reply.started":"2023-05-31T01:55:45.293801Z"},"trusted":true},"outputs":[],"source":["show(sample)"]},{"cell_type":"markdown","metadata":{},"source":["## Transformer that performs the extra data augmentations\n","\n","transformer v2 has these functions exclusively, do not mistake it for transformer v1 functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:55:45.304813Z","iopub.status.busy":"2023-05-31T01:55:45.304453Z","iopub.status.idle":"2023-05-31T01:55:45.315232Z","shell.execute_reply":"2023-05-31T01:55:45.313958Z","shell.execute_reply.started":"2023-05-31T01:55:45.304781Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose(\n","    [\n","        transforms.RandomPhotometricDistort(),        \n","        transforms.RandomAutocontrast(),\n","        transforms.RandomEqualize(),\n","        transforms.GaussianBlur(kernel_size=3),\n","        # transforms.ToImageTensor(),\n","        transforms.PILToTensor(),\n","        transforms.ConvertImageDtype(torch.float32),\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Create a dataset using wrapper function of transformer v2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:57:49.420446Z","iopub.status.busy":"2023-05-31T01:57:49.419752Z","iopub.status.idle":"2023-05-31T01:58:21.183584Z","shell.execute_reply":"2023-05-31T01:58:21.182418Z","shell.execute_reply.started":"2023-05-31T01:57:49.420403Z"},"trusted":true},"outputs":[],"source":["# del coco_train\n","coco_train = load_dataset(transform=transform)\n","coco_train = dset.wrap_dataset_for_transforms_v2(coco_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:27.313645Z","iopub.status.busy":"2023-05-31T01:58:27.313242Z","iopub.status.idle":"2023-05-31T01:58:27.753472Z","shell.execute_reply":"2023-05-31T01:58:27.752324Z","shell.execute_reply.started":"2023-05-31T01:58:27.313599Z"},"trusted":true},"outputs":[],"source":["sample = coco_train[1]\n","show(sample)"]},{"cell_type":"markdown","metadata":{},"source":["## Create a Dataset class for getting single sample and apply transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:32.182969Z","iopub.status.busy":"2023-05-31T01:58:32.182417Z","iopub.status.idle":"2023-05-31T01:58:32.245911Z","shell.execute_reply":"2023-05-31T01:58:32.244506Z","shell.execute_reply.started":"2023-05-31T01:58:32.182921Z"},"trusted":true},"outputs":[],"source":["class NewCocoDataset(Dataset):    \n","    def __init__(self, coco_dataset, image_size=(312, 312)):\n","        \"\"\"\n","        Arguments:\n","            coco_dataset (dataset): The coco dataset containing all the expected transforms.\n","            image_size (tuple): Target image size. Default is (512, 512)\n","        \"\"\"\n","        \n","        self.coco_dataset = coco_dataset\n","        self.resize = Resize(image_size)\n","        self.rhf = RandomHorizontalFlip()\n","        self.rvf = RandomVerticalFlip()   \n","        self.transformer = transforms.Compose([\n","            # transforms.ToImageTensor(),\n","            transforms.PILToTensor(),\n","            transforms.ConvertImageDtype(torch.float32),\n","        ])\n","\n","        \n","    def __len__(self):\n","        return len(self.coco_dataset)\n","    \n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","        new_target = {}\n","        \n","        image, target = self.coco_dataset[idx]\n","        \n","        if 'boxes' not in target:    \n","            new_idx = idx-1\n","            _img, _t = self.coco_dataset[new_idx]\n","            while 'boxes' not in _t :\n","                new_idx -= 1\n","                _img, _t = self.coco_dataset[new_idx]\n","                \n","            image, target = self.coco_dataset[new_idx]\n","        \n","        \n","        image, bboxes = image, target[\"boxes\"] \n","            \n","        image, bboxes = self.resize(image, bboxes)\n","        image, bboxes = self.rhf(image, bboxes)\n","        image, bboxes = self.rvf(image, bboxes)\n","        \n","        image = self.transformer(image)\n","        \n","        new_boxes = []\n","        for box in bboxes:\n","            if box[0] < box[2] and box[1] < box[3]:\n","                new_boxes.append(box)\n","        \n","        new_target[\"boxes\"] = torch.stack(new_boxes)\n","        new_target[\"labels\"] = target[\"labels\"]\n","    \n","        return (image, new_target)"]},{"cell_type":"markdown","metadata":{},"source":["## Custom Batching\n","This class gives a different Batching solution for `CPU` and `GPU`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:35.007011Z","iopub.status.busy":"2023-05-31T01:58:35.006576Z","iopub.status.idle":"2023-05-31T01:58:35.016214Z","shell.execute_reply":"2023-05-31T01:58:35.014559Z","shell.execute_reply.started":"2023-05-31T01:58:35.006976Z"},"trusted":true},"outputs":[],"source":["class CustomBatchs:\n","    def __init__(self, data):\n","        transposed_data = list(zip(*data))\n","        self.inp = torch.stack(transposed_data[0], 0)\n","        self.tgt = transposed_data[1]\n","\n","    # custom memory pinning method on custom type\n","    def pin_memory(self):\n","        self.inp = self.inp.pin_memory()\n","        return (self.inp, self.tgt)\n","    \n","def collate_wrapper(batch):\n","    if torch.cuda.is_available():\n","        return CustomBatchs(batch)\n","    else:\n","        return tuple(zip(*batch))"]},{"cell_type":"markdown","metadata":{},"source":["## Create a dataset loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:36.847484Z","iopub.status.busy":"2023-05-31T01:58:36.847070Z","iopub.status.idle":"2023-05-31T01:58:40.239954Z","shell.execute_reply":"2023-05-31T01:58:40.238644Z","shell.execute_reply.started":"2023-05-31T01:58:36.847448Z"},"trusted":true},"outputs":[],"source":["new_coco_train = NewCocoDataset(coco_train)\n","\n","data_loader = torch.utils.data.DataLoader(\n","    new_coco_train,\n","    batch_size=50 if not USING_CPU else 8,\n","    shuffle=True,\n","    # collate_fn=lambda batch: tuple(zip(*batch)),\n","    collate_fn=collate_wrapper,\n","    **kwargs\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:42.677397Z","iopub.status.busy":"2023-05-31T01:58:42.677016Z","iopub.status.idle":"2023-05-31T01:58:42.682334Z","shell.execute_reply":"2023-05-31T01:58:42.681155Z","shell.execute_reply.started":"2023-05-31T01:58:42.677365Z"},"trusted":true},"outputs":[],"source":["for img, tar in tqdm(data_loader):\n","    pass"]},{"cell_type":"markdown","metadata":{},"source":["## Get the names and their corresponding indices"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T02:15:03.721571Z","iopub.status.busy":"2023-05-31T02:15:03.721153Z","iopub.status.idle":"2023-05-31T02:15:31.261233Z","shell.execute_reply":"2023-05-31T02:15:31.259876Z","shell.execute_reply.started":"2023-05-31T02:15:03.721534Z"},"trusted":true},"outputs":[],"source":["import pycocotools.coco\n","\n","coco_anns = pycocotools.coco.COCO(TRAIN_ANN_FILE)\n","catIDs = coco_anns.getCatIds()\n","cats = coco_anns.loadCats(catIDs)\n","\n","name_idx = {}\n","\n","for sub_dict in cats:\n","    name_idx[sub_dict[\"id\"]] = sub_dict[\"name\"]\n","    \n","del coco_anns, catIDs, cats"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:45.152258Z","iopub.status.busy":"2023-05-31T01:58:45.151864Z","iopub.status.idle":"2023-05-31T01:58:46.362872Z","shell.execute_reply":"2023-05-31T01:58:46.361485Z","shell.execute_reply.started":"2023-05-31T01:58:45.152228Z"},"trusted":true},"outputs":[],"source":["data = next(iter(data_loader))\n","if USING_CPU:\n","    x = torch.stack(data[0])\n","else:\n","    x = data[0]\n","print(x.shape)\n","# _labels = [name_idx[i] for i in data[1][0]['labels'].tolist()]\n","# print(_labels)\n","\n","plt.imshow(data[0][0].permute(1, 2, 0).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:51.157594Z","iopub.status.busy":"2023-05-31T01:58:51.157086Z","iopub.status.idle":"2023-05-31T01:58:51.167003Z","shell.execute_reply":"2023-05-31T01:58:51.166014Z","shell.execute_reply.started":"2023-05-31T01:58:51.157550Z"},"trusted":true},"outputs":[],"source":["data[1][0]['boxes']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:52.167537Z","iopub.status.busy":"2023-05-31T01:58:52.166890Z","iopub.status.idle":"2023-05-31T01:58:52.175389Z","shell.execute_reply":"2023-05-31T01:58:52.174135Z","shell.execute_reply.started":"2023-05-31T01:58:52.167500Z"},"trusted":true},"outputs":[],"source":["data[0][0].shape, data[0][1].shape"]},{"cell_type":"markdown","metadata":{},"source":["## Load the base model\n","\n","`ssd300_vgg16` is used for training."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:53.482697Z","iopub.status.busy":"2023-05-31T01:58:53.482280Z","iopub.status.idle":"2023-05-31T01:58:57.063126Z","shell.execute_reply":"2023-05-31T01:58:57.061899Z","shell.execute_reply.started":"2023-05-31T01:58:53.482663Z"},"trusted":true},"outputs":[],"source":["base_model = models.get_model(\"ssd300_vgg16\", weights=None, weights_backbone=None).train()"]},{"cell_type":"markdown","metadata":{},"source":["## Old Model uses VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:58.517660Z","iopub.status.busy":"2023-05-31T01:58:58.516910Z","iopub.status.idle":"2023-05-31T01:58:58.522433Z","shell.execute_reply":"2023-05-31T01:58:58.521170Z","shell.execute_reply.started":"2023-05-31T01:58:58.517592Z"},"trusted":true},"outputs":[],"source":["# base_model"]},{"cell_type":"markdown","metadata":{},"source":["## New Model uses VGG19 `Removed_for_now`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:58:58.857348Z","iopub.status.busy":"2023-05-31T01:58:58.856948Z","iopub.status.idle":"2023-05-31T01:58:58.862160Z","shell.execute_reply":"2023-05-31T01:58:58.860895Z","shell.execute_reply.started":"2023-05-31T01:58:58.857317Z"},"trusted":true},"outputs":[],"source":["# new_feature_extractor = models.vgg19(weights=None).train()\n","# base_model.backbone.features = new_feature_extractor.features[:27]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:00.256783Z","iopub.status.busy":"2023-05-31T01:59:00.256345Z","iopub.status.idle":"2023-05-31T01:59:00.261587Z","shell.execute_reply":"2023-05-31T01:59:00.260359Z","shell.execute_reply.started":"2023-05-31T01:59:00.256748Z"},"trusted":true},"outputs":[],"source":["# base_model"]},{"cell_type":"markdown","metadata":{},"source":["## Initalize the weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:00.406868Z","iopub.status.busy":"2023-05-31T01:59:00.406448Z","iopub.status.idle":"2023-05-31T01:59:00.413632Z","shell.execute_reply":"2023-05-31T01:59:00.412147Z","shell.execute_reply.started":"2023-05-31T01:59:00.406834Z"},"trusted":true},"outputs":[],"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:00.567141Z","iopub.status.busy":"2023-05-31T01:59:00.566735Z","iopub.status.idle":"2023-05-31T01:59:00.854739Z","shell.execute_reply":"2023-05-31T01:59:00.853407Z","shell.execute_reply.started":"2023-05-31T01:59:00.567109Z"},"trusted":true},"outputs":[],"source":["base_model.apply(weights_init)\n","print(DEVICE)\n","\n","if (DEVICE.type == 'cuda') and (n_gpus > 1):\n","    base_model = nn.DataParallel(base_model, list(range(n_gpus)))"]},{"cell_type":"markdown","metadata":{},"source":["## Display the loaded model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:00.857085Z","iopub.status.busy":"2023-05-31T01:59:00.856725Z","iopub.status.idle":"2023-05-31T01:59:00.869444Z","shell.execute_reply":"2023-05-31T01:59:00.868326Z","shell.execute_reply.started":"2023-05-31T01:59:00.857054Z"},"trusted":true},"outputs":[],"source":["base_model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:00.876553Z","iopub.status.busy":"2023-05-31T01:59:00.876014Z","iopub.status.idle":"2023-05-31T01:59:00.884963Z","shell.execute_reply":"2023-05-31T01:59:00.883852Z","shell.execute_reply.started":"2023-05-31T01:59:00.876517Z"},"trusted":true},"outputs":[],"source":["total_params = sum(p.numel() for p in base_model.parameters())\n","print(f'{total_params:,} total parameters.')\n","total_trainable_params = sum(\n","    p.numel() for p in base_model.parameters() if p.requires_grad)\n","print(f'{total_trainable_params:,} training parameters.')"]},{"cell_type":"markdown","metadata":{},"source":["## Model Hyper Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:03.746958Z","iopub.status.busy":"2023-05-31T01:59:03.746534Z","iopub.status.idle":"2023-05-31T01:59:03.753306Z","shell.execute_reply":"2023-05-31T01:59:03.752162Z","shell.execute_reply.started":"2023-05-31T01:59:03.746925Z"},"trusted":true},"outputs":[],"source":["learning_rate = 1e-4\n","\n","optimizer = optim.Adam(base_model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T01:59:58.958868Z","iopub.status.busy":"2023-05-31T01:59:58.958147Z","iopub.status.idle":"2023-05-31T02:00:04.180367Z","shell.execute_reply":"2023-05-31T02:00:04.179312Z","shell.execute_reply.started":"2023-05-31T01:59:58.958830Z"},"trusted":true},"outputs":[],"source":["if USE_PRETRAINED:\n","    new_LR = 1e-5 # change this value to set a new Learning Rate for the version of notebook\n","    \n","    if USING_CPU:\n","        checkpoint = torch.load(SAVED_MODEL_PATH, map_location=torch.device('mps'))\n","    else:\n","        checkpoint = torch.load(SAVED_MODEL_PATH)\n","        \n","    base_model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    for g in optimizer.param_groups:\n","        g['lr'] = new_LR"]},{"cell_type":"markdown","metadata":{},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T02:00:05.747304Z","iopub.status.busy":"2023-05-31T02:00:05.746525Z","iopub.status.idle":"2023-05-31T02:00:05.757119Z","shell.execute_reply":"2023-05-31T02:00:05.756067Z","shell.execute_reply.started":"2023-05-31T02:00:05.747257Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T02:00:06.227456Z","iopub.status.busy":"2023-05-31T02:00:06.226572Z","iopub.status.idle":"2023-05-31T02:00:06.231726Z","shell.execute_reply":"2023-05-31T02:00:06.230436Z","shell.execute_reply.started":"2023-05-31T02:00:06.227420Z"},"trusted":true},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T18:45:20.099911Z","iopub.status.busy":"2023-05-16T18:45:20.099562Z","iopub.status.idle":"2023-05-16T18:46:53.558626Z","shell.execute_reply":"2023-05-16T18:46:53.556946Z","shell.execute_reply.started":"2023-05-16T18:45:20.099877Z"},"trusted":true},"outputs":[],"source":["for epoch in range(EPOCHS):\n","    running_classifier_loss = 0.0\n","    running_bbox_loss = 0.0\n","    running_loss = 0.0\n","    \n","    counter = 0\n","    base_model.train()\n","    \n","    for data_point in tqdm(data_loader):\n","        _i, _t = data_point[0], data_point[1]\n","        \n","        if USING_CPU:\n","            _i = torch.stack(_i)\n","\n","#         _t = torch.from_numpy(np.asarray(_t))\n","        \n","        _i = _i.to(DEVICE)\n","        _t = [{k: v.to(DEVICE) for k, v in __t.items()} for __t in _t]\n","\n","        optimizer.zero_grad()\n","\n","\n","        loss_dict = base_model(_i, _t)\n","        \n","#         running_bbox_loss += torch.mean(loss_dict['bbox_regression']).item()\n","#         running_classifier_loss += torch.mean(loss_dict['classification']).item()\n","\n","        losses = sum(loss for loss in loss_dict.values())\n","    \n","        losses.backward()\n","        optimizer.step()\n","        \n","        running_loss += losses.item()\n","        \n","        del loss_dict, losses\n","        \n","        counter += 1\n","        \n","        if counter % 500 == 499:\n","            last_classifier_loss = running_classifier_loss / 500 # loss per batch\n","            last_bbox_loss = running_bbox_loss / 500 # loss per batch\n","            last_loss = running_loss / 500 # loss per batch\n","#             print(f'batch {counter + 1} Classification Loss: {last_classifier_loss}', end='')\n","#             print(f', BBox Loss: {last_bbox_loss}')\n","            print(f'Epoch {epoch}, Batch {counter + 1}, Running Loss: {last_loss}')\n","            running_classifier_loss = 0.0\n","            running_bbox_loss = 0.0\n","            running_loss = 0.0\n","            \n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T18:46:56.245623Z","iopub.status.busy":"2023-05-16T18:46:56.244872Z","iopub.status.idle":"2023-05-16T18:46:58.184249Z","shell.execute_reply":"2023-05-16T18:46:58.182554Z","shell.execute_reply.started":"2023-05-16T18:46:56.245575Z"},"trusted":true},"outputs":[],"source":["gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## Use an image from Validation Set and Display the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T02:24:53.476286Z","iopub.status.busy":"2023-05-31T02:24:53.475832Z","iopub.status.idle":"2023-05-31T02:24:54.255458Z","shell.execute_reply":"2023-05-31T02:24:54.254375Z","shell.execute_reply.started":"2023-05-31T02:24:53.476254Z"},"trusted":true},"outputs":[],"source":["VAL_IMG_DIR = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\n","VAL_ANN_FILE = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\n","\n","\n","def load_val_dataset(transform):\n","    return dset.CocoDetection(root = VAL_IMG_DIR, \n","                              annFile = VAL_ANN_FILE)\n","\n","val_transform = transforms.Compose(\n","    [\n","        transforms.ToImageTensor(),\n","        transforms.ConvertImageDtype(torch.float32),\n","    ]\n",")\n","coco_val = load_val_dataset(transform=val_transform)\n","coco_val = dset.wrap_dataset_for_transforms_v2(coco_val)\n","\n","new_coco_val = NewCocoDataset(coco_val)\n","val_data_loader = torch.utils.data.DataLoader(\n","    new_coco_val,\n","    batch_size=50 if not USING_CPU else 8,\n","    shuffle=True,\n","#     collate_fn=lambda batch: tuple(zip(*batch)),\n","    collate_fn=collate_wrapper,\n","     **kwargs\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-31T02:31:25.711786Z","iopub.status.busy":"2023-05-31T02:31:25.710927Z","iopub.status.idle":"2023-05-31T02:31:32.898308Z","shell.execute_reply":"2023-05-31T02:31:32.896754Z","shell.execute_reply.started":"2023-05-31T02:31:25.711731Z"},"trusted":true},"outputs":[],"source":["img_dtype_converter = transforms.ConvertImageDtype(torch.uint8)\n","data = next(iter(val_data_loader))\n","\n","_i = data[0]\n","\n","threshold = 0.5\n","idx = 3\n","\n","if USING_CPU:\n","    _i = torch.stack(_i)\n","\n","_i = _i.to(DEVICE)\n","base_model.eval()\n","p_t = base_model(_i)\n","\n","confidence_length = len(np.argwhere(p_t[idx]['scores'] > threshold)[0])\n","\n","p_boxes = p_t[idx]['boxes'][: confidence_length]\n","p_labels = [name_idx[i] for i in p_t[idx]['labels'][: confidence_length].tolist()]\n","i_img = img_dtype_converter(_i[idx])\n","\n","annotated_image = draw_bounding_boxes(i_img, p_boxes, p_labels, colors=\"yellow\", width=3)\n","fig, ax = plt.subplots()\n","ax.imshow(annotated_image.permute(1, 2, 0).numpy())\n","ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","fig.tight_layout()\n","\n","\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Save and Load Model along with its states"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T20:48:49.157503Z","iopub.status.busy":"2023-05-13T20:48:49.156471Z","iopub.status.idle":"2023-05-13T20:48:49.359481Z","shell.execute_reply":"2023-05-13T20:48:49.358502Z","shell.execute_reply.started":"2023-05-13T20:48:49.157464Z"},"trusted":true},"outputs":[],"source":["PATH = '/kaggle/working/ssd300_vgg16_checkpoint_2'\n","\n","torch.save({\n","            'epoch': EPOCHS,\n","            'model_state_dict': base_model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            }, PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-13T20:48:49.439895Z","iopub.status.busy":"2023-05-13T20:48:49.439396Z","iopub.status.idle":"2023-05-13T20:48:49.449589Z","shell.execute_reply":"2023-05-13T20:48:49.448564Z","shell.execute_reply.started":"2023-05-13T20:48:49.439857Z"},"trusted":true},"outputs":[],"source":["checkpoint = torch.load(PATH)\n","base_model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
