{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms,models\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "device=torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [08:22<00:00, 339590.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "traindir = \"data/training\"\n",
    "testdir = \"data/validation\"\n",
    "\n",
    "#transformations\n",
    "train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                       transforms.ToTensor(),                                \n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                           mean=[0.485, 0.456, 0.406],\n",
    "                                           std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "                                       ])\n",
    "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      torchvision.transforms.Normalize(\n",
    "                                          mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "                                      ])\n",
    "\n",
    "#datasets\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, optimizer, loss_fn):\n",
    "  def train_step(x,y):\n",
    "    #make prediction\n",
    "    yhat = model(x)\n",
    "    #enter train mode\n",
    "    model.train()\n",
    "    #compute loss\n",
    "    loss = loss_fn(yhat,y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #optimizer.cleargrads()\n",
    "\n",
    "    return loss\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datascience/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datascience/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "#freeze all params\n",
    "for params in model.parameters():\n",
    "  params.requires_grad_ = False\n",
    "\n",
    "#add a new final layer\n",
    "nr_filters = model.fc.in_features  #number of input features of last layer\n",
    "model.fc = nn.Linear(nr_filters, 1)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "loss_fn = BCEWithLogitsLoss() #binary cross entropy with sigmoid, so no need to use sigmoid in the model\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.fc.parameters()) \n",
    "\n",
    "#train step\n",
    "train_step = make_train_step(model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [05:21<00:00, 38.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1, train loss : -9181.263671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, val loss : -15878.314453125\n",
      "/nTerminating: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "\n",
    "n_epochs = 10\n",
    "early_stopping_tolerance = 3\n",
    "early_stopping_threshold = 0.03\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i ,data in tqdm(enumerate(trainloader), total = len(trainloader)): #iterate ove batches\n",
    "        x_batch , y_batch = data\n",
    "        x_batch = x_batch.to(device) #move to gpu\n",
    "        y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
    "        y_batch = y_batch.to(device) #move to gpu\n",
    "\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        epoch_loss += loss/len(trainloader)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    epoch_train_losses.append(epoch_loss)\n",
    "    print('\\nEpoch : {}, train loss : {}'.format(epoch+1,epoch_loss))\n",
    "\n",
    "#validation doesnt requires gradient\n",
    "    with torch.no_grad():\n",
    "        cum_loss = 0\n",
    "        for x_batch, y_batch in testloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.unsqueeze(1).float() #convert target to same nn output shape\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "        #model to eval mode\n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_batch)\n",
    "            val_loss = loss_fn(yhat,y_batch)\n",
    "            cum_loss += loss/len(testloader)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "        epoch_test_losses.append(cum_loss)\n",
    "        print('Epoch : {}, val loss : {}'.format(epoch+1,cum_loss))  \n",
    "    \n",
    "        best_loss = min(epoch_test_losses)\n",
    "    \n",
    "    #save best model\n",
    "        if cum_loss <= best_loss:\n",
    "            best_model_wts = model.state_dict()\n",
    "        \n",
    "        #early stopping\n",
    "        early_stopping_counter = 0\n",
    "        if cum_loss > best_loss:\n",
    "            early_stopping_counter +=1\n",
    "\n",
    "        if (early_stopping_counter == early_stopping_tolerance) or (best_loss <= early_stopping_threshold):\n",
    "            print(\"/nTerminating: early stopping\")\n",
    "            break #terminate training\n",
    "#load best model\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_data):\n",
    "  idx = torch.randint(1, len(test_data), (1,))\n",
    "  sample = torch.unsqueeze(test_data[idx][0], dim=0).to(device)\n",
    "\n",
    "  if torch.sigmoid(model(sample)) < 0.5:\n",
    "    print(\"Prediction : Cat\")\n",
    "  else:\n",
    "    print(\"Prediction : Dog\")\n",
    "\n",
    "\n",
    "  plt.imshow(test_data[idx][0].permute(1, 2, 0))\n",
    "\n",
    "inference(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
